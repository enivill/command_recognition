paths:
  raw_data_root: data/external/speech_commands_v0.01/
  dataset_root: data/datasets/without_outliers/
  pairs_root: data/pairs/without_outliers_w100/
  dataset_name:
    train: train.txt
    val: val.txt
    test: test.txt
  pairs_name:
    train: train_pairs.csv
    val: val_pairs.csv
    test: test_pairs.csv
  results_csv: model_results.csv

split:
  delete_outlier: True
  duration_limit: 1.0
  percentage:
    train: 60
    val: 20
    test: 20

make_pairs:
  order: [ 'train', 'val', 'test' ]  # do not change
  word_per_class_train: 500 # use null if you want to load all the data
  excluded_classes: # _background_noise_ is automatically excluded
    train: [ ]
    val: [ ]
    test: [ ]
  percentage:
    train: 60
    val: 20
    test: 20

feature_extraction:
  sample_rate: 16000
  window_length_seconds: 20
  hop_length_seconds: 10
  n_mels: 50
  n_mfcc: 16
  f_min: 0
  f_max: 8000


train:
  log:
    dir: models/
    name: mel_1aa/
  batch_size: 128
  epochs: 1
  feature_type: mel   # mfcc, stft, mel
  learning_rate: 0.001


layers:
  cnn:
    num_of_layers: 2
    conv:
      filters: [32, 32]
      kernel: [3,2]
      stride: [1,1]
      activation: ['relu', 'relu']
    batchnorm: [True, True]
    dropout: [0.1, 0.2]
    pool:
      size: [2,2]
      stride: [2,2]
  flt: True
  GlobalAveragePooling: False
  dns:
    num_of_layers: 2
    units: [512, 128]
    activation: [ "relu", "relu"]
    dropout: [0.2, 0.2]

after_distance:
  dns:
    num_of_layers: 0
    units: [  ]
    activation: [  ]
    dropout: [  ]






