
# INITIAL SETTINGS
raw_data_root: data/external/speech_commands_v0.01/
#classes: ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']

# AUDIO LENGTH
delete_outlier: True
duration_limit: 1.0

# SPLIT DATA
dataset_root: data/datasets/without_outliers/
dataset_name:
  train: train.txt
  val: val.txt
  test: test.txt
percentage:
  train: 60
  val: 20
  test: 20

# MAKE PAIRS
word_per_class_train: 500 # use null if you want to load all the data
excluded_classes: # _background_noise_ is automatically excluded
  train: [ ]
  val: [ ]
  test: [ ]
order: [ 'train', 'val', 'test' ]  # do not change
pairs_root: data/pairs/without_outliers_w500/
pairs_name:
  train: train_pairs.csv
  val: val_pairs.csv
  test: test_pairs.csv

# FEATURE EXTRACTION
sample_rate: 16000
n_fft: 512
window_length: 512  # same as n_fft
hop_length: 128   # window_length // 2
n_mels: 128
n_mfcc: 15
f_min: 50
f_max: 4000


# TRAIN
log:
  dir: models/
  name: siamese_no2/
batch_size: 128
epochs: 20
feature_type: mfcc   # mfcc, stft, mel
learning_rate: 0.001

# for MFCC - number of MFCCs, n_mfcc
# for mel, number of Mel bands, n_mels
input_dim_a: 126
input_dim_b: 15


# BASE NETWORK
layers:
  cnn:
    num_of_layers: 2
    conv:
      filters: [64, 64]
      kernel: [[20,4],[10,2]]
      stride: [[1,2],1]
      activation: ['relu', 'relu']
    batchnorm: [True, True]
    dropout: [null, 0.2]
    pool:
      size: [[1,3],null]
      stride: [[1,3],null]


  flt: True
  GlobalAveragePooling: False
  dns:
    num_of_layers: 2
    units: [32, 128]
    activation: [ "relu", "relu"]
    dropout: [null, 0.2]





